[llm]# llm config
name='groq:llama-3.3-70b-versatile'
base_url=''
api_key="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"
max_tokens=1024
temperature=0.0 # The "temperature" parameter in a Large Language Model (LLM) controls the randomness and creativity of the generated text, with lower values resulting in more predictable and conservative outputs, and higher values leading to more diverse and creative outputs. 
prompt='''
    You are an AI assistant that converts natural language queries to SQL.

    Follow these guidelines:
    - Always use the knowledge base that is provided the context in between <schema> </schema> tags to answer the questions.
    - Generate sql query based on the information retrieved from the knowledge base
    - provide only the sql query in your response

'''

[embedder] # text embedding model config
model='sentence-transformers/all-MiniLM-L6-v2'
token="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"
normalize=true


[chunker] # chunker config
chunk_strategy="table_level" # "field_level"

[retriever] # retriever config
top_k=10

[reranker] # Text reranking model config
model="BAAI/bge-reranker-base"
token="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"
top_k=4

[file_paths]# Data files names and paths config
src_dir="D:/DataFiles/datatext-to-sql-qa-bot"
db_file="db/chinook.sqlite"
kb_dir="kb"
vector_db_dir="vector_db"
eval_file="eval/chinook_eval.json"
eval_file_with_response="eval/chinook_eval_with_response.json"
results_dir="results"

[logfire]#logfire config
token="SGtFQXq0qRhrb6xKjhYt0pGkWSVHY395z3cv4X10jV6C"

[judge_llm]#Evaluator or Judge LLM config
name="gemma2-9b-it"
base_url=""
api_key="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"
max_tokens=1024
temparature=0.0
prompt=""


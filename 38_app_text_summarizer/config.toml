[llm] # llm config
name = "groq:llama-3.3-70b-versatile"
base_url = ""
api_key = "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"
max_tokens = 1024
temperature = 0.0
prompt= '''
You are a text summarizer to summarize news articles. Write a short one sentence summary.
'''

[file_paths] # Data files names and paths config
src_dir = "D:/DataFiles/text_summarizer"
eval_file = "eval/news_short.json"
eval_file_with_response = "eval/news_short_with_response.json"
results_dir = "results"
results_non_llm_metrics_file="report_non_llm_metrics.txt"

[docs] # Document length config
short_doc_threshold = 5000
medium_doc_threshold = 10000
long_doc_threshold = 20000

[chunker] # chunker config
chunk_size = 2048
chunk_overlap = 128

[embedder] # Text embedding Model config
model='sentence-transformers/all-MiniLM-L6-v2'
token="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"
normalize = true

[logfire] # log fire config
token = "SGtFQXq0qRhrb6xKjhYt0pGkWSVHY395z3cv4X10jV6C"
 
[judge_llm] # Evaluator/Judge LLM config
name="gemma2-9b-it"
base_url=""
api_key="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"
max_tokens=1024
temperature=0.0
prompt=""
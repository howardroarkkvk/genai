max_iter = 3

[llm_generator]
# name = "groq:deepseek-r1-distill-llama-70b"
# name = "groq:gemma2-9b-it"
name = "github:openai/gpt-4.1-mini"
base_url = "https://models.github.ai/inference"
api_key = "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"
max_tokens = 1024
temperature = 0.0

[file_paths]
src_dir = "D:/DataFiles/code_contests"
eval_file = "eval/eval.jsonl"
results_file = "results/results_direct.jsonl"

[logfire] 
token = 'SGtFQXq0qRhrb6xKjhYt0pGkWSVHY395z3cv4X10jV6C'